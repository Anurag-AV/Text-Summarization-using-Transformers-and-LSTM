{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe148a72-f57e-4ce9-bf3f-40371bb259ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import math\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# ============================================================================\n",
    "# HYPERPARAMETERS\n",
    "# ============================================================================\n",
    "class Config:\n",
    "    # Data parameters\n",
    "    train_file = 'train.csv'\n",
    "    val_file = 'validation.csv'\n",
    "    test_file = 'test.csv'\n",
    "\n",
    "    # BPE Tokenizer parameters\n",
    "    vocab_size = 50000\n",
    "    tokenizer_file = 'bpe_tokenizer_all.pkl'\n",
    "\n",
    "    # Model parameters (INCREASED DEPTH)\n",
    "    d_model = 512\n",
    "    n_heads = 8\n",
    "    n_encoder_layers = 8  # INCREASED from 4 to 8 (2x deeper)\n",
    "    n_decoder_layers = 8  # INCREASED from 4 to 8 (2x deeper)\n",
    "    d_ff = 2048\n",
    "    dropout = 0.1\n",
    "    max_seq_len = 512\n",
    "    max_summary_len = 64\n",
    "\n",
    "    # Training parameters (adjusted for deeper network)\n",
    "    batch_size = 24  # Slightly reduced due to increased memory from deeper model\n",
    "    learning_rate = 0.0005  # Reduced for more stable training with deeper network\n",
    "    n_epochs = 37\n",
    "    warmup_steps = 4000  # Increased warmup for deeper network\n",
    "    gradient_clip = 0.5  # Tighter clipping for deeper network stability\n",
    "    label_smoothing = 0.1\n",
    "    gradient_accumulation_steps = 2  # Increased to maintain effective batch size\n",
    "\n",
    "    # Data sampling for faster training\n",
    "    max_train_samples = 250\n",
    "    max_val_samples = 100\n",
    "    max_test_samples = 100\n",
    "\n",
    "    # Generation parameters\n",
    "    beam_size = 5\n",
    "    length_penalty = 0.6\n",
    "    top_k_summaries = 5\n",
    "    max_generation_batches = 100\n",
    "\n",
    "    # Model saving\n",
    "    model_file = 'transformer_summarization_deep.pt'\n",
    "    vocab_file = 'vocabulary.pkl'\n",
    "\n",
    "    # Device\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    # Performance optimizations\n",
    "    num_workers = 0\n",
    "    pin_memory = True if torch.cuda.is_available() else False\n",
    "    compile_model = False\n",
    "    use_flash_attention = False\n",
    "\n",
    "    # Progress settings\n",
    "    log_interval = 50\n",
    "    validate_every_n_epochs = 1\n",
    "\n",
    "config = Config()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad1c2337-767b-4f6d-85ef-47b332173c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# BPE TOKENIZER FROM SCRATCH (OPTIMIZED)\n",
    "# ============================================================================\n",
    "class BPETokenizer:\n",
    "    def __init__(self, vocab_size=50000):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.word_freqs = {}\n",
    "        self.splits = {}\n",
    "        self.merges = {}\n",
    "        self.vocab = {}\n",
    "        self.special_tokens = {\n",
    "            '<PAD>': 0,\n",
    "            '<UNK>': 1,\n",
    "            '<SOS>': 2,\n",
    "            '<EOS>': 3\n",
    "        }\n",
    "\n",
    "    def train(self, texts, progress=True, max_samples=1000000):\n",
    "        \"\"\"Train BPE tokenizer on texts\"\"\"\n",
    "        print(\"Training BPE tokenizer (optimized)...\")\n",
    "\n",
    "        # Sample texts if too many\n",
    "        if len(texts) > max_samples:\n",
    "            print(f\"Sampling {max_samples} texts from {len(texts)} for faster training...\")\n",
    "            import random\n",
    "            texts = random.sample(texts, max_samples)\n",
    "\n",
    "        # Count word frequencies (optimized with batch processing)\n",
    "        print(\"Computing word frequencies...\")\n",
    "        word_counter = Counter()\n",
    "        for text in tqdm(texts, disable=not progress):\n",
    "            words = self._pre_tokenize(text)\n",
    "            word_counter.update(words)\n",
    "\n",
    "        # Keep only top words for efficiency\n",
    "        max_words = 50000\n",
    "        if len(word_counter) > max_words:\n",
    "            print(f\"Keeping top {max_words} most frequent words...\")\n",
    "            self.word_freqs = dict(word_counter.most_common(max_words))\n",
    "        else:\n",
    "            self.word_freqs = dict(word_counter)\n",
    "\n",
    "        # Initialize splits (character level)\n",
    "        print(\"Initializing character-level splits...\")\n",
    "        alphabet = set()\n",
    "        for word in self.word_freqs.keys():\n",
    "            alphabet.update(word)\n",
    "\n",
    "        # Build initial vocabulary with special tokens\n",
    "        self.vocab = self.special_tokens.copy()\n",
    "        for char in sorted(alphabet):\n",
    "            self.vocab[char] = len(self.vocab)\n",
    "\n",
    "        # Initialize splits with tuples for immutability (faster)\n",
    "        self.splits = {word: tuple(word) for word in self.word_freqs.keys()}\n",
    "\n",
    "        # Learn merges\n",
    "        num_merges = self.vocab_size - len(self.vocab)\n",
    "        print(f\"Learning {num_merges} merges...\")\n",
    "\n",
    "        # Cache pair positions for faster updates\n",
    "        self.pair_cache = {}\n",
    "        self._build_pair_cache()\n",
    "\n",
    "        for i in tqdm(range(num_merges), disable=not progress):\n",
    "            # Get most frequent pair from cache\n",
    "            pair_freqs = self._compute_pair_freqs_cached()\n",
    "            if not pair_freqs:\n",
    "                break\n",
    "\n",
    "            best_pair = max(pair_freqs, key=pair_freqs.get)\n",
    "            merged = best_pair[0] + best_pair[1]\n",
    "            self.merges[best_pair] = merged\n",
    "            self.vocab[merged] = len(self.vocab)\n",
    "\n",
    "            # Update splits efficiently (only words containing the pair)\n",
    "            self._update_splits_cached(best_pair, merged)\n",
    "\n",
    "        print(f\"Vocabulary size: {len(self.vocab)}\")\n",
    "\n",
    "        # Clear cache to save memory\n",
    "        self.pair_cache = None\n",
    "\n",
    "    def _pre_tokenize(self, text):\n",
    "        \"\"\"Pre-tokenize text into words\"\"\"\n",
    "        if not isinstance(text, str):\n",
    "            text = str(text)\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^a-z0-9\\s\\.,!?;:\\'\\\"-]', '', text)\n",
    "        return text.split()\n",
    "\n",
    "    def _build_pair_cache(self):\n",
    "        \"\"\"Build cache of which words contain which pairs\"\"\"\n",
    "        self.pair_cache = defaultdict(set)\n",
    "        for word in self.word_freqs.keys():\n",
    "            split = self.splits[word]\n",
    "            for i in range(len(split) - 1):\n",
    "                pair = (split[i], split[i + 1])\n",
    "                self.pair_cache[pair].add(word)\n",
    "\n",
    "    def _compute_pair_freqs_cached(self):\n",
    "        \"\"\"Compute frequency of character pairs using cache\"\"\"\n",
    "        pair_freqs = defaultdict(int)\n",
    "        for pair, words in self.pair_cache.items():\n",
    "            for word in words:\n",
    "                split = self.splits[word]\n",
    "                # Count occurrences of pair in this split\n",
    "                count = sum(1 for i in range(len(split) - 1)\n",
    "                           if split[i] == pair[0] and split[i + 1] == pair[1])\n",
    "                pair_freqs[pair] += count * self.word_freqs[word]\n",
    "        return pair_freqs\n",
    "\n",
    "    def _update_splits_cached(self, pair, merged):\n",
    "        \"\"\"Update splits only for words containing the pair\"\"\"\n",
    "        words_to_update = self.pair_cache[pair].copy()\n",
    "\n",
    "        # Remove old pair from cache\n",
    "        del self.pair_cache[pair]\n",
    "\n",
    "        for word in words_to_update:\n",
    "            old_split = self.splits[word]\n",
    "            new_split = []\n",
    "            i = 0\n",
    "\n",
    "            while i < len(old_split):\n",
    "                if i < len(old_split) - 1 and old_split[i] == pair[0] and old_split[i + 1] == pair[1]:\n",
    "                    new_split.append(merged)\n",
    "                    i += 2\n",
    "                else:\n",
    "                    new_split.append(old_split[i])\n",
    "                    i += 1\n",
    "\n",
    "            self.splits[word] = tuple(new_split)\n",
    "\n",
    "            # Update cache with new pairs\n",
    "            for i in range(len(new_split) - 1):\n",
    "                new_pair = (new_split[i], new_split[i + 1])\n",
    "                self.pair_cache[new_pair].add(word)\n",
    "\n",
    "    def _merge_pair(self, split, pair):\n",
    "        \"\"\"Merge a pair in a split\"\"\"\n",
    "        new_split = []\n",
    "        i = 0\n",
    "        while i < len(split):\n",
    "            if i < len(split) - 1 and split[i] == pair[0] and split[i + 1] == pair[1]:\n",
    "                new_split.append(self.merges[pair])\n",
    "                i += 2\n",
    "            else:\n",
    "                new_split.append(split[i])\n",
    "                i += 1\n",
    "        return new_split\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        \"\"\"Tokenize text using learned BPE (optimized)\"\"\"\n",
    "        words = self._pre_tokenize(text)\n",
    "        tokens = []\n",
    "\n",
    "        # Create merge priority lookup (lower index = higher priority)\n",
    "        merge_priority = {pair: idx for idx, pair in enumerate(self.merges.keys())}\n",
    "\n",
    "        for word in words:\n",
    "            # Get initial split\n",
    "            split = list(word)\n",
    "\n",
    "            # Apply merges efficiently\n",
    "            while len(split) > 1:\n",
    "                # Find all possible pairs\n",
    "                pairs = [(i, (split[i], split[i + 1]))\n",
    "                        for i in range(len(split) - 1)]\n",
    "\n",
    "                # Filter to only valid merges and find highest priority\n",
    "                valid_merges = [(i, pair) for i, pair in pairs if pair in merge_priority]\n",
    "\n",
    "                if not valid_merges:\n",
    "                    break\n",
    "\n",
    "                # Get pair with highest priority (lowest index)\n",
    "                min_pos, min_pair = min(valid_merges, key=lambda x: merge_priority[x[1]])\n",
    "\n",
    "                # Merge the pair\n",
    "                split = split[:min_pos] + [self.merges[min_pair]] + split[min_pos + 2:]\n",
    "\n",
    "            tokens.extend(split)\n",
    "\n",
    "        return tokens\n",
    "\n",
    "    def encode(self, text, add_special_tokens=True):\n",
    "        \"\"\"Encode text to token IDs\"\"\"\n",
    "        tokens = self.tokenize(text)\n",
    "        ids = []\n",
    "\n",
    "        if add_special_tokens:\n",
    "            ids.append(self.special_tokens['<SOS>'])\n",
    "\n",
    "        for token in tokens:\n",
    "            ids.append(self.vocab.get(token, self.special_tokens['<UNK>']))\n",
    "\n",
    "        if add_special_tokens:\n",
    "            ids.append(self.special_tokens['<EOS>'])\n",
    "\n",
    "        return ids\n",
    "\n",
    "    def decode(self, ids, skip_special_tokens=True):\n",
    "        \"\"\"Decode token IDs to text\"\"\"\n",
    "        id_to_token = {v: k for k, v in self.vocab.items()}\n",
    "        tokens = []\n",
    "\n",
    "        for id in ids:\n",
    "            token = id_to_token.get(id, '<UNK>')\n",
    "            if skip_special_tokens and token in self.special_tokens:\n",
    "                continue\n",
    "            tokens.append(token)\n",
    "\n",
    "        # Join tokens with spaces for readability\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "    def save(self, filepath):\n",
    "        \"\"\"Save tokenizer\"\"\"\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump({\n",
    "                'vocab_size': self.vocab_size,\n",
    "                'word_freqs': self.word_freqs,\n",
    "                'splits': self.splits,\n",
    "                'merges': self.merges,\n",
    "                'vocab': self.vocab,\n",
    "                'special_tokens': self.special_tokens\n",
    "            }, f)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, filepath):\n",
    "        \"\"\"Load tokenizer\"\"\"\n",
    "        with open(filepath, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "\n",
    "        # Handle both old and new pickle formats\n",
    "        tokenizer = cls(data.get('vocab_size', 10000))\n",
    "        tokenizer.word_freqs = data.get('word_freqs', {})\n",
    "        tokenizer.splits = data.get('splits', {})\n",
    "        tokenizer.merges = data.get('merges', {})\n",
    "        tokenizer.vocab = data.get('vocab', {})\n",
    "        tokenizer.special_tokens = data.get('special_tokens', {\n",
    "            '<PAD>': 0,\n",
    "            '<UNK>': 1,\n",
    "            '<SOS>': 2,\n",
    "            '<EOS>': 3\n",
    "        })\n",
    "\n",
    "        return tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "157d17f0-00a8-4203-8056-563acc9f37e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SUMMARIZER\n",
    "# ============================================================================\n",
    "class SummarizationDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_article_len, max_summary_len):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_article_len = max_article_len\n",
    "        self.max_summary_len = max_summary_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        article = str(self.df.iloc[idx]['article'])\n",
    "        summary = str(self.df.iloc[idx]['highlights'])\n",
    "\n",
    "        # Encode\n",
    "        article_ids = self.tokenizer.encode(article, add_special_tokens=True)\n",
    "        summary_ids = self.tokenizer.encode(summary, add_special_tokens=True)\n",
    "\n",
    "        # Truncate\n",
    "        article_ids = article_ids[:self.max_article_len]\n",
    "        summary_ids = summary_ids[:self.max_summary_len]\n",
    "\n",
    "        return {\n",
    "            'article': torch.tensor(article_ids, dtype=torch.long),\n",
    "            'summary': torch.tensor(summary_ids, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Collate function with padding\"\"\"\n",
    "    articles = [item['article'] for item in batch]\n",
    "    summaries = [item['summary'] for item in batch]\n",
    "\n",
    "    # Pad sequences\n",
    "    article_lens = [len(a) for a in articles]\n",
    "    summary_lens = [len(s) for s in summaries]\n",
    "\n",
    "    max_article_len = max(article_lens)\n",
    "    max_summary_len = max(summary_lens)\n",
    "\n",
    "    padded_articles = torch.zeros(len(batch), max_article_len, dtype=torch.long)\n",
    "    padded_summaries = torch.zeros(len(batch), max_summary_len, dtype=torch.long)\n",
    "\n",
    "    for i, (article, summary) in enumerate(zip(articles, summaries)):\n",
    "        padded_articles[i, :len(article)] = article\n",
    "        padded_summaries[i, :len(summary)] = summary\n",
    "\n",
    "    return {\n",
    "        'article': padded_articles,\n",
    "        'summary': padded_summaries,\n",
    "        'article_mask': (padded_articles != 0).unsqueeze(1).unsqueeze(2),\n",
    "        'summary_mask': (padded_summaries != 0).unsqueeze(1).unsqueeze(2)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d3ffdaf-d102-408a-b75a-721b1db9270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TRANSFORMER INTERNALS\n",
    "# ============================================================================\n",
    "\n",
    "# ============================================================================\n",
    "# POSITIONAL ENCODING\n",
    "# ============================================================================\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]\n",
    "\n",
    "# ============================================================================\n",
    "# MULTI-HEAD ATTENTION\n",
    "# ============================================================================\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % n_heads == 0\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_model // n_heads\n",
    "\n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        batch_size = query.size(0)\n",
    "\n",
    "        # Linear projections\n",
    "        Q = self.W_q(query).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        K = self.W_k(key).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        V = self.W_v(value).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "        # Attention\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "\n",
    "        if mask is not None:\n",
    "            # Use -1e4 instead of -1e9 to avoid float16 overflow\n",
    "            scores = scores.masked_fill(mask == 0, -1e4)\n",
    "\n",
    "        attention = F.softmax(scores, dim=-1)\n",
    "        attention = self.dropout(attention)\n",
    "\n",
    "        # Apply attention to values\n",
    "        x = torch.matmul(attention, V)\n",
    "\n",
    "        # Concatenate heads\n",
    "        x = x.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
    "\n",
    "        # Final linear projection\n",
    "        x = self.W_o(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# ============================================================================\n",
    "# FEED FORWARD NETWORK\n",
    "# ============================================================================\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear2(self.dropout(F.relu(self.linear1(x))))\n",
    "\n",
    "# ============================================================================\n",
    "# ENCODER LAYER (with Pre-LN for better deep network training)\n",
    "# ============================================================================\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, n_heads, dropout)\n",
    "        self.feed_forward = FeedForward(d_model, d_ff, dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # Pre-LN: Layer norm before attention (better for deep networks)\n",
    "        normed = self.norm1(x)\n",
    "        attn_output = self.self_attn(normed, normed, normed, mask)\n",
    "        x = x + self.dropout(attn_output)\n",
    "\n",
    "        # Pre-LN: Layer norm before feed-forward\n",
    "        normed = self.norm2(x)\n",
    "        ff_output = self.feed_forward(normed)\n",
    "        x = x + self.dropout(ff_output)\n",
    "\n",
    "        return x\n",
    "\n",
    "# ============================================================================\n",
    "# DECODER LAYER (with Pre-LN for better deep network training)\n",
    "# ============================================================================\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, n_heads, dropout)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, n_heads, dropout)\n",
    "        self.feed_forward = FeedForward(d_model, d_ff, dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
    "        # Pre-LN: Layer norm before self-attention\n",
    "        normed = self.norm1(x)\n",
    "        attn_output = self.self_attn(normed, normed, normed, tgt_mask)\n",
    "        x = x + self.dropout(attn_output)\n",
    "\n",
    "        # Pre-LN: Layer norm before cross-attention\n",
    "        normed = self.norm2(x)\n",
    "        attn_output = self.cross_attn(normed, encoder_output, encoder_output, src_mask)\n",
    "        x = x + self.dropout(attn_output)\n",
    "\n",
    "        # Pre-LN: Layer norm before feed-forward\n",
    "        normed = self.norm3(x)\n",
    "        ff_output = self.feed_forward(normed)\n",
    "        x = x + self.dropout(ff_output)\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb397f42-3823-4bf7-8318-b32d78e272a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TRANSFORMER MODEL (with final layer norms for Pre-LN architecture)\n",
    "# ============================================================================\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, n_heads, n_encoder_layers,\n",
    "                 n_decoder_layers, d_ff, max_seq_len, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.encoder_embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.decoder_embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(d_model, max_seq_len)\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, n_heads, d_ff, dropout)\n",
    "            for _ in range(n_encoder_layers)\n",
    "        ])\n",
    "\n",
    "        self.decoder_layers = nn.ModuleList([\n",
    "            DecoderLayer(d_model, n_heads, d_ff, dropout)\n",
    "            for _ in range(n_decoder_layers)\n",
    "        ])\n",
    "\n",
    "        # Final layer norms for Pre-LN architecture\n",
    "        self.encoder_norm = nn.LayerNorm(d_model)\n",
    "        self.decoder_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        \"\"\"Xavier initialization with adjusted scaling for deeper networks\"\"\"\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p, gain=1.0)\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        x = self.encoder_embedding(src) * math.sqrt(self.d_model)\n",
    "        x = self.pos_encoding(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for layer in self.encoder_layers:\n",
    "            x = layer(x, src_mask)\n",
    "\n",
    "        # Final layer norm for Pre-LN architecture\n",
    "        x = self.encoder_norm(x)\n",
    "        return x\n",
    "\n",
    "    def decode(self, tgt, encoder_output, src_mask, tgt_mask):\n",
    "        x = self.decoder_embedding(tgt) * math.sqrt(self.d_model)\n",
    "        x = self.pos_encoding(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for layer in self.decoder_layers:\n",
    "            x = layer(x, encoder_output, src_mask, tgt_mask)\n",
    "\n",
    "        # Final layer norm for Pre-LN architecture\n",
    "        x = self.decoder_norm(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        encoder_output = self.encode(src, src_mask)\n",
    "        decoder_output = self.decode(tgt, encoder_output, src_mask, tgt_mask)\n",
    "        output = self.fc_out(decoder_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6672ab8-6d46-46b4-b3e6-ed7ad6e61010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# BEAM SEARCH\n",
    "# ============================================================================\n",
    "class BeamSearch:\n",
    "    def __init__(self, model, tokenizer, beam_size=4, max_len=128, length_penalty=0.6):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.beam_size = beam_size\n",
    "        self.max_len = max_len\n",
    "        self.length_penalty = length_penalty\n",
    "        self.sos_id = tokenizer.special_tokens['<SOS>']\n",
    "        self.eos_id = tokenizer.special_tokens['<EOS>']\n",
    "        self.pad_id = tokenizer.special_tokens['<PAD>']\n",
    "\n",
    "    def generate(self, src, src_mask):\n",
    "        \"\"\"Generate summary using beam search\"\"\"\n",
    "        self.model.eval()\n",
    "        batch_size = src.size(0)\n",
    "        device = src.device\n",
    "\n",
    "        # Encode source\n",
    "        encoder_output = self.model.encode(src, src_mask)\n",
    "\n",
    "        # Initialize beams: (batch_size, beam_size, seq_len)\n",
    "        beams = torch.full((batch_size, self.beam_size, 1), self.sos_id, dtype=torch.long, device=device)\n",
    "        beam_scores = torch.zeros(batch_size, self.beam_size, device=device)\n",
    "        beam_scores[:, 1:] = -1e9  # Only first beam is active initially\n",
    "\n",
    "        completed_beams = [[] for _ in range(batch_size)]\n",
    "\n",
    "        for step in range(self.max_len - 1):\n",
    "            # Prepare decoder input\n",
    "            tgt = beams.view(batch_size * self.beam_size, -1)\n",
    "\n",
    "            # Create target mask\n",
    "            tgt_len = tgt.size(1)\n",
    "            tgt_mask = torch.tril(torch.ones(tgt_len, tgt_len, device=device)).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "            # Expand encoder output for beam search\n",
    "            encoder_output_expanded = encoder_output.unsqueeze(1).repeat(1, self.beam_size, 1, 1)\n",
    "            encoder_output_expanded = encoder_output_expanded.view(batch_size * self.beam_size, -1, self.model.d_model)\n",
    "\n",
    "            src_mask_expanded = src_mask.unsqueeze(1).repeat(1, self.beam_size, 1, 1, 1)\n",
    "            src_mask_expanded = src_mask_expanded.view(batch_size * self.beam_size, 1, 1, -1)\n",
    "\n",
    "            # Decode\n",
    "            with torch.no_grad():\n",
    "                decoder_output = self.model.decode(tgt, encoder_output_expanded, src_mask_expanded, tgt_mask)\n",
    "                logits = self.model.fc_out(decoder_output[:, -1, :])\n",
    "                log_probs = F.log_softmax(logits, dim=-1)\n",
    "\n",
    "            # Reshape log probs\n",
    "            log_probs = log_probs.view(batch_size, self.beam_size, -1)\n",
    "\n",
    "            # Calculate scores\n",
    "            vocab_size = log_probs.size(-1)\n",
    "            scores = beam_scores.unsqueeze(-1) + log_probs\n",
    "            scores = scores.view(batch_size, -1)\n",
    "\n",
    "            # Get top k scores and indices\n",
    "            top_scores, top_indices = torch.topk(scores, self.beam_size, dim=-1)\n",
    "\n",
    "            # Calculate which beam and which token\n",
    "            beam_indices = top_indices // vocab_size\n",
    "            token_indices = top_indices % vocab_size\n",
    "\n",
    "            # Update beams - maintain structure per batch\n",
    "            new_beams_by_batch = [[] for _ in range(batch_size)]\n",
    "            new_scores_by_batch = [[] for _ in range(batch_size)]\n",
    "\n",
    "            for b in range(batch_size):\n",
    "                for i in range(self.beam_size):\n",
    "                    beam_idx = beam_indices[b, i]\n",
    "                    token_idx = token_indices[b, i]\n",
    "\n",
    "                    # Get previous beam\n",
    "                    prev_beam = beams[b, beam_idx]\n",
    "\n",
    "                    # Check if EOS\n",
    "                    if token_idx == self.eos_id:\n",
    "                        # Apply length penalty\n",
    "                        score = top_scores[b, i] / ((prev_beam.size(0) + 1) ** self.length_penalty)\n",
    "                        completed_beams[b].append((prev_beam.tolist() + [token_idx.item()], score.item()))\n",
    "                        # Add a dummy beam to maintain beam_size count\n",
    "                        new_beams_by_batch[b].append(prev_beam)  # Keep the previous beam\n",
    "                        new_scores_by_batch[b].append(torch.tensor(-1e9, device=device))  # Very low score\n",
    "                    else:\n",
    "                        new_beam = torch.cat([prev_beam, token_idx.unsqueeze(0)])\n",
    "                        new_beams_by_batch[b].append(new_beam)\n",
    "                        new_scores_by_batch[b].append(top_scores[b, i])\n",
    "\n",
    "            # Check if all beams are completed\n",
    "            if all(len(completed_beams[b]) >= self.beam_size for b in range(batch_size)):\n",
    "                break\n",
    "\n",
    "            # Convert to tensor (pad if necessary)\n",
    "            max_len = max(max(beam.size(0) for beam in batch_beams) for batch_beams in new_beams_by_batch)\n",
    "            \n",
    "            all_beams = []\n",
    "            all_scores = []\n",
    "            \n",
    "            for b in range(batch_size):\n",
    "                batch_beams = []\n",
    "                for beam in new_beams_by_batch[b]:\n",
    "                    if beam.size(0) < max_len:\n",
    "                        padding = torch.full((max_len - beam.size(0),), self.pad_id, dtype=torch.long, device=device)\n",
    "                        beam = torch.cat([beam, padding])\n",
    "                    batch_beams.append(beam)\n",
    "                all_beams.append(torch.stack(batch_beams))\n",
    "                all_scores.append(torch.stack(new_scores_by_batch[b]))\n",
    "\n",
    "            beams = torch.stack(all_beams)\n",
    "            beam_scores = torch.stack(all_scores)\n",
    "\n",
    "        # Get best beam for each batch\n",
    "        results = []\n",
    "        for b in range(batch_size):\n",
    "            if completed_beams[b]:\n",
    "                best_beam = max(completed_beams[b], key=lambda x: x[1])[0]\n",
    "            else:\n",
    "                best_beam = beams[b, 0].tolist()\n",
    "            results.append(best_beam)\n",
    "\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9ce2854-317e-42ce-9bc9-685b1d77c7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# BLEU SCORE FROM SCRATCH\n",
    "# ============================================================================\n",
    "class BLEUScore:\n",
    "    def __init__(self, max_n=4):\n",
    "        self.max_n = max_n\n",
    "\n",
    "    def _get_ngrams(self, tokens, n):\n",
    "        \"\"\"Get n-grams from tokens\"\"\"\n",
    "        ngrams = []\n",
    "        for i in range(len(tokens) - n + 1):\n",
    "            ngrams.append(tuple(tokens[i:i+n]))\n",
    "        return ngrams\n",
    "\n",
    "    def _modified_precision(self, reference, hypothesis, n):\n",
    "        \"\"\"Calculate modified n-gram precision\"\"\"\n",
    "        ref_ngrams = Counter(self._get_ngrams(reference, n))\n",
    "        hyp_ngrams = Counter(self._get_ngrams(hypothesis, n))\n",
    "\n",
    "        if not hyp_ngrams:\n",
    "            return 0.0\n",
    "\n",
    "        clipped_counts = {}\n",
    "        for ngram in hyp_ngrams:\n",
    "            clipped_counts[ngram] = min(hyp_ngrams[ngram], ref_ngrams.get(ngram, 0))\n",
    "\n",
    "        numerator = sum(clipped_counts.values())\n",
    "        denominator = sum(hyp_ngrams.values())\n",
    "\n",
    "        return numerator / denominator if denominator > 0 else 0.0\n",
    "\n",
    "    def _brevity_penalty(self, reference, hypothesis):\n",
    "        \"\"\"Calculate brevity penalty\"\"\"\n",
    "        ref_len = len(reference)\n",
    "        hyp_len = len(hypothesis)\n",
    "\n",
    "        if hyp_len > ref_len:\n",
    "            return 1.0\n",
    "        elif hyp_len == 0:\n",
    "            return 0.0\n",
    "        else:\n",
    "            return math.exp(1 - ref_len / hyp_len)\n",
    "\n",
    "    def compute(self, references, hypotheses):\n",
    "        \"\"\"\n",
    "        Compute BLEU score\n",
    "        references: list of reference token lists\n",
    "        hypotheses: list of hypothesis token lists\n",
    "        \"\"\"\n",
    "        assert len(references) == len(hypotheses)\n",
    "\n",
    "        precisions = [[] for _ in range(self.max_n)]\n",
    "        total_ref_len = 0\n",
    "        total_hyp_len = 0\n",
    "\n",
    "        for ref, hyp in zip(references, hypotheses):\n",
    "            total_ref_len += len(ref)\n",
    "            total_hyp_len += len(hyp)\n",
    "\n",
    "            for n in range(1, self.max_n + 1):\n",
    "                prec = self._modified_precision(ref, hyp, n)\n",
    "                precisions[n-1].append(prec)\n",
    "\n",
    "        # Average precisions\n",
    "        avg_precisions = [sum(p) / len(p) if p else 0.0 for p in precisions]\n",
    "\n",
    "        # Geometric mean of precisions\n",
    "        if min(avg_precisions) > 0:\n",
    "            geo_mean = math.exp(sum(math.log(p) for p in avg_precisions) / self.max_n)\n",
    "        else:\n",
    "            geo_mean = 0.0\n",
    "\n",
    "        # Brevity penalty\n",
    "        if total_hyp_len > total_ref_len:\n",
    "            bp = 1.0\n",
    "        elif total_hyp_len == 0:\n",
    "            bp = 0.0\n",
    "        else:\n",
    "            bp = math.exp(1 - total_ref_len / total_hyp_len)\n",
    "\n",
    "        bleu = bp * geo_mean\n",
    "\n",
    "        return {\n",
    "            'bleu': bleu,\n",
    "            'precisions': avg_precisions,\n",
    "            'brevity_penalty': bp,\n",
    "            'length_ratio': total_hyp_len / total_ref_len if total_ref_len > 0 else 0.0\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a54c3c4-c9a8-4910-bd4a-34055a4bc26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TRAINING\n",
    "# ============================================================================\n",
    "def create_masks(src, tgt, pad_id=0):\n",
    "    \"\"\"Create masks for source and target\"\"\"\n",
    "    # Source mask (batch_size, 1, 1, src_len)\n",
    "    src_mask = (src != pad_id).unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "    # Target mask (causal) - convert to bool first\n",
    "    tgt_len = tgt.size(1)\n",
    "    tgt_mask = torch.tril(torch.ones(tgt_len, tgt_len, device=tgt.device, dtype=torch.bool)).unsqueeze(0).unsqueeze(0)\n",
    "    tgt_pad_mask = (tgt != pad_id).unsqueeze(1).unsqueeze(2)\n",
    "    tgt_mask = tgt_mask & tgt_pad_mask\n",
    "\n",
    "    return src_mask, tgt_mask\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, criterion, device, config, scaler=None):\n",
    "    \"\"\"Train for one epoch with mixed precision and gradient accumulation\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    pbar = tqdm(dataloader, desc='Training', dynamic_ncols=True)\n",
    "    for batch_idx, batch in enumerate(pbar):\n",
    "        src = batch['article'].to(device, non_blocking=True)\n",
    "        tgt = batch['summary'].to(device, non_blocking=True)\n",
    "\n",
    "        # Create masks\n",
    "        src_mask, tgt_mask = create_masks(src, tgt[:, :-1])\n",
    "\n",
    "        # Mixed precision training\n",
    "        if scaler is not None:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                output = model(src, tgt[:, :-1], src_mask, tgt_mask)\n",
    "                output = output.reshape(-1, output.size(-1))\n",
    "                tgt_out = tgt[:, 1:].reshape(-1)\n",
    "                loss = criterion(output, tgt_out) / config.gradient_accumulation_steps\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if (batch_idx + 1) % config.gradient_accumulation_steps == 0:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), config.gradient_clip)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "        else:\n",
    "            output = model(src, tgt[:, :-1], src_mask, tgt_mask)\n",
    "            output = output.reshape(-1, output.size(-1))\n",
    "            tgt_out = tgt[:, 1:].reshape(-1)\n",
    "            loss = criterion(output, tgt_out) / config.gradient_accumulation_steps\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            if (batch_idx + 1) % config.gradient_accumulation_steps == 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), config.gradient_clip)\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        total_loss += loss.item() * config.gradient_accumulation_steps\n",
    "\n",
    "        # Update progress bar less frequently\n",
    "        if batch_idx % config.log_interval == 0:\n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{loss.item() * config.gradient_accumulation_steps:.4f}',\n",
    "                'avg': f'{total_loss/(batch_idx+1):.4f}'\n",
    "            }, refresh=False)\n",
    "\n",
    "    return total_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "517cda26-9215-4e47-bbe1-2fcd0fa1351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, criterion, device, config, tokenizer=None, compute_bleu=False):\n",
    "    \"\"\"Validate model (faster version) with optional BLEU computation\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    # For BLEU computation\n",
    "    references = []\n",
    "    hypotheses = []\n",
    "    max_bleu_batches = 20  # Compute BLEU on subset for speed\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(dataloader, desc='Validating', dynamic_ncols=True)\n",
    "        for batch_idx, batch in enumerate(pbar):\n",
    "            src = batch['article'].to(device, non_blocking=True)\n",
    "            tgt = batch['summary'].to(device, non_blocking=True)\n",
    "\n",
    "            # Create masks\n",
    "            src_mask, tgt_mask = create_masks(src, tgt[:, :-1])\n",
    "\n",
    "            # Forward pass with mixed precision\n",
    "            if config.device == 'cuda':\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    output = model(src, tgt[:, :-1], src_mask, tgt_mask)\n",
    "                    output = output.reshape(-1, output.size(-1))\n",
    "                    tgt_out = tgt[:, 1:].reshape(-1)\n",
    "                    loss = criterion(output, tgt_out)\n",
    "            else:\n",
    "                output = model(src, tgt[:, :-1], src_mask, tgt_mask)\n",
    "                output = output.reshape(-1, output.size(-1))\n",
    "                tgt_out = tgt[:, 1:].reshape(-1)\n",
    "                loss = criterion(output, tgt_out)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "            # Compute BLEU on subset\n",
    "            if compute_bleu and tokenizer and batch_idx < max_bleu_batches:\n",
    "                # Simple greedy decoding for BLEU (faster than beam search)\n",
    "                predictions = output.argmax(dim=-1).view(src.size(0), -1)\n",
    "                \n",
    "                for i in range(src.size(0)):\n",
    "                    # Reference\n",
    "                    ref_ids = tgt[i].cpu().tolist()\n",
    "                    ref_ids = [id for id in ref_ids if id not in [\n",
    "                        tokenizer.special_tokens['<PAD>'],\n",
    "                        tokenizer.special_tokens['<SOS>'],\n",
    "                        tokenizer.special_tokens['<EOS>']\n",
    "                    ]]\n",
    "                    references.append(ref_ids)\n",
    "                    \n",
    "                    # Hypothesis\n",
    "                    hyp_ids = predictions[i].cpu().tolist()\n",
    "                    hyp_ids = [id for id in hyp_ids if id not in [\n",
    "                        tokenizer.special_tokens['<PAD>'],\n",
    "                        tokenizer.special_tokens['<SOS>'],\n",
    "                        tokenizer.special_tokens['<EOS>']\n",
    "                    ]]\n",
    "                    hypotheses.append(hyp_ids)\n",
    "    \n",
    "    avg_loss = total_loss / num_batches\n",
    "    \n",
    "    # Compute BLEU if requested\n",
    "    bleu_score = None\n",
    "    if compute_bleu and tokenizer and references:\n",
    "        bleu_scorer = BLEUScore()\n",
    "        bleu_results = bleu_scorer.compute(references, hypotheses)\n",
    "        bleu_score = bleu_results['bleu']\n",
    "    \n",
    "    return avg_loss, bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f93050c2-7bbb-4420-bf88-27ae0235016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZATION\n",
    "# ============================================================================\n",
    "def plot_training_curves(train_losses, val_losses, val_bleu_scores, save_path='training_curves.png'):\n",
    "    \"\"\"\n",
    "    Plot training and validation curves\n",
    "    \n",
    "    Args:\n",
    "        train_losses: List of training losses per epoch\n",
    "        val_losses: List of validation losses per epoch (with None for non-validation epochs)\n",
    "        val_bleu_scores: List of BLEU scores per epoch (with None for non-validation epochs)\n",
    "        save_path: Path to save the plot\n",
    "    \"\"\"\n",
    "    # Filter out None values for validation metrics\n",
    "    val_epochs = [i for i, loss in enumerate(val_losses) if loss is not None]\n",
    "    val_losses_filtered = [loss for loss in val_losses if loss is not None]\n",
    "    val_bleu_filtered = [bleu for bleu in val_bleu_scores if bleu is not None]\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    # Plot 1: Training Loss\n",
    "    axes[0].plot(range(len(train_losses)), train_losses, 'b-', linewidth=2, label='Training Loss')\n",
    "    axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[0].set_ylabel('Loss', fontsize=12)\n",
    "    axes[0].set_title('Training Loss over Epochs', fontsize=14, fontweight='bold')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # Plot 2: Training vs Validation Loss\n",
    "    axes[1].plot(range(len(train_losses)), train_losses, 'b-', linewidth=2, label='Training Loss', alpha=0.7)\n",
    "    if val_losses_filtered:\n",
    "        axes[1].plot(val_epochs, val_losses_filtered, 'r-', linewidth=2, marker='o', \n",
    "                     markersize=6, label='Validation Loss')\n",
    "    axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[1].set_ylabel('Loss', fontsize=12)\n",
    "    axes[1].set_title('Training vs Validation Loss', fontsize=14, fontweight='bold')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    axes[1].legend()\n",
    "    \n",
    "    # Plot 3: BLEU Score\n",
    "    if val_bleu_filtered:\n",
    "        axes[2].plot(val_epochs, val_bleu_filtered, 'g-', linewidth=2, marker='s', \n",
    "                     markersize=6, label='Validation BLEU')\n",
    "        axes[2].set_xlabel('Epoch', fontsize=12)\n",
    "        axes[2].set_ylabel('BLEU Score', fontsize=12)\n",
    "        axes[2].set_title('BLEU Score over Epochs', fontsize=14, fontweight='bold')\n",
    "        axes[2].grid(True, alpha=0.3)\n",
    "        axes[2].legend()\n",
    "        \n",
    "        # Add best BLEU annotation\n",
    "        if val_bleu_filtered:\n",
    "            best_bleu = max(val_bleu_filtered)\n",
    "            best_epoch = val_epochs[val_bleu_filtered.index(best_bleu)]\n",
    "            axes[2].axhline(y=best_bleu, color='r', linestyle='--', alpha=0.5, linewidth=1)\n",
    "            axes[2].text(0.02, 0.98, f'Best BLEU: {best_bleu:.4f} (Epoch {best_epoch+1})', \n",
    "                        transform=axes[2].transAxes, verticalalignment='top',\n",
    "                        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    else:\n",
    "        axes[2].text(0.5, 0.5, 'No BLEU scores available', \n",
    "                    ha='center', va='center', transform=axes[2].transAxes, fontsize=14)\n",
    "        axes[2].set_title('BLEU Score over Epochs', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Add overall statistics\n",
    "    fig.suptitle(f'Training Progress - {len(train_losses)} Epochs', \n",
    "                 fontsize=16, fontweight='bold', y=1.02)\n",
    "    \n",
    "    # Add timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    fig.text(0.99, 0.01, f'Generated: {timestamp}', ha='right', fontsize=8, alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"âœ“ Training curves saved to {save_path}\")\n",
    "    \n",
    "    # Also display if in notebook\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        plt.show()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "011f5117-a24d-4e2c-95dd-b5532351b807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CHECKPOINT LOADING AND SAVING\n",
    "# ============================================================================\n",
    "def save_checkpoint(epoch, model, optimizer, scheduler, scaler, val_loss, train_losses, val_losses, val_bleu_scores, config):\n",
    "    \"\"\"Save training checkpoint with atomic write to prevent corruption\"\"\"\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "        'scaler_state_dict': scaler.state_dict() if scaler else None,\n",
    "        'val_loss': val_loss,\n",
    "        'train_losses': train_losses,  # Save loss history\n",
    "        'val_losses': val_losses,      # Save validation loss history\n",
    "        'val_bleu_scores': val_bleu_scores,  # Save BLEU score history\n",
    "        'config': {\n",
    "            'n_encoder_layers': config.n_encoder_layers,\n",
    "            'n_decoder_layers': config.n_decoder_layers,\n",
    "            'd_model': config.d_model,\n",
    "            'n_heads': config.n_heads,\n",
    "            'd_ff': config.d_ff,\n",
    "            'vocab_size': config.vocab_size,\n",
    "            'max_seq_len': config.max_seq_len,\n",
    "            'dropout': config.dropout\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Atomic save: write to temp file first, then rename\n",
    "    temp_file = config.model_file + '.tmp'\n",
    "    try:\n",
    "        torch.save(checkpoint, temp_file)\n",
    "        # Rename is atomic on most systems\n",
    "        if os.path.exists(config.model_file):\n",
    "            os.replace(temp_file, config.model_file)\n",
    "        else:\n",
    "            os.rename(temp_file, config.model_file)\n",
    "        print(f\"âœ“ Checkpoint saved to {config.model_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error saving checkpoint: {e}\")\n",
    "        if os.path.exists(temp_file):\n",
    "            os.remove(temp_file)\n",
    "\n",
    "def load_checkpoint(model, optimizer, scheduler, scaler, config):\n",
    "    \"\"\"Load training checkpoint if it exists\"\"\"\n",
    "    if not os.path.exists(config.model_file):\n",
    "        print(\"No checkpoint found. Starting training from scratch.\")\n",
    "        return 0, float('inf'), [], [], []\n",
    "    \n",
    "    print(f\"Loading checkpoint from {config.model_file}...\")\n",
    "    \n",
    "    try:\n",
    "        # Load checkpoint with weights_only=False since we have optimizer/scheduler state\n",
    "        checkpoint = torch.load(config.model_file, map_location=config.device, weights_only=False)\n",
    "        \n",
    "        # Load model state\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(\"âœ“ Model state loaded\")\n",
    "        \n",
    "        # Load optimizer state\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        print(\"âœ“ Optimizer state loaded\")\n",
    "        \n",
    "        # Load scheduler state if available\n",
    "        if scheduler and checkpoint.get('scheduler_state_dict'):\n",
    "            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "            print(\"âœ“ Scheduler state loaded\")\n",
    "        \n",
    "        # Load scaler state if available\n",
    "        if scaler and checkpoint.get('scaler_state_dict'):\n",
    "            scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
    "            print(\"âœ“ Scaler state loaded\")\n",
    "        \n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        best_val_loss = checkpoint.get('val_loss', float('inf'))\n",
    "        \n",
    "        # Load loss histories (with defaults for backward compatibility)\n",
    "        train_losses = checkpoint.get('train_losses', [])\n",
    "        val_losses = checkpoint.get('val_losses', [])\n",
    "        val_bleu_scores = checkpoint.get('val_bleu_scores', [])\n",
    "        \n",
    "        print(f\"âœ“ Resuming from epoch {start_epoch}\")\n",
    "        print(f\"âœ“ Best validation loss: {best_val_loss:.4f}\")\n",
    "        print(f\"âœ“ Loaded {len(train_losses)} training loss records\")\n",
    "        \n",
    "        return start_epoch, best_val_loss, train_losses, val_losses, val_bleu_scores\n",
    "        \n",
    "    except (RuntimeError, EOFError, pickle.UnpicklingError, Exception) as e:\n",
    "        print(f\"âœ— Error loading checkpoint: {e}\")\n",
    "        print(\"âœ— Checkpoint file appears to be corrupted.\")\n",
    "        \n",
    "        # Create backup of corrupted file\n",
    "        backup_file = config.model_file + '.corrupted'\n",
    "        print(f\"Creating backup at: {backup_file}\")\n",
    "        try:\n",
    "            os.rename(config.model_file, backup_file)\n",
    "            print(\"âœ“ Corrupted checkpoint backed up.\")\n",
    "        except:\n",
    "            print(\"âœ— Could not backup corrupted file. Deleting it.\")\n",
    "            os.remove(config.model_file)\n",
    "        \n",
    "        print(\"Starting training from scratch.\")\n",
    "        return 0, float('inf'), [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d29b3edf-f23b-4cbf-81ca-6039c8e1044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "def main():\n",
    "    print(\"=\" * 80)\n",
    "    print(\"DEEPER TRANSFORMER TEXT SUMMARIZATION (WITH RESUME CAPABILITY)\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Device: {config.device}\")\n",
    "    print(f\"Model Depth: {config.n_encoder_layers} encoder layers, {config.n_decoder_layers} decoder layers\")\n",
    "    print()\n",
    "\n",
    "    # Load or train tokenizer\n",
    "    print(\"Step 1: Loading/Training Tokenizer\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    tokenizer = None\n",
    "    if os.path.exists(config.tokenizer_file):\n",
    "        try:\n",
    "            print(f\"Loading tokenizer from {config.tokenizer_file}\")\n",
    "            tokenizer = BPETokenizer.load(config.tokenizer_file)\n",
    "            print(\"Tokenizer loaded successfully!\")\n",
    "        except (KeyError, EOFError, pickle.UnpicklingError) as e:\n",
    "            print(f\"Error loading tokenizer: {e}\")\n",
    "            print(\"Deleting corrupted tokenizer file and training new one...\")\n",
    "            os.remove(config.tokenizer_file)\n",
    "            tokenizer = None\n",
    "\n",
    "    if tokenizer is None:\n",
    "        print(\"Training new tokenizer...\")\n",
    "        # Load training data\n",
    "        train_df = pd.read_csv(config.train_file)\n",
    "\n",
    "        # Combine articles and summaries for tokenizer training\n",
    "        texts = train_df['article'].tolist() + train_df['highlights'].tolist()\n",
    "\n",
    "        tokenizer = BPETokenizer(vocab_size=config.vocab_size)\n",
    "        tokenizer.train(texts)\n",
    "        tokenizer.save(config.tokenizer_file)\n",
    "        print(f\"Tokenizer saved to {config.tokenizer_file}\")\n",
    "\n",
    "    print(f\"Vocabulary size: {len(tokenizer.vocab)}\")\n",
    "    \n",
    "    # Save vocabulary immediately\n",
    "    print(\"Saving vocabulary...\")\n",
    "    with open(config.vocab_file, 'wb') as f:\n",
    "        pickle.dump(tokenizer.vocab, f)\n",
    "    print(f\"âœ“ Vocabulary saved to {config.vocab_file}\")\n",
    "    print()\n",
    "\n",
    "    # Load datasets\n",
    "    print(\"Step 2: Loading Datasets\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    train_df = pd.read_csv(config.train_file)\n",
    "    val_df = pd.read_csv(config.val_file)\n",
    "    test_df = pd.read_csv(config.test_file)\n",
    "\n",
    "    # Sample datasets for faster training\n",
    "    if len(train_df) > config.max_train_samples:\n",
    "        print(f\"Sampling {config.max_train_samples} from {len(train_df)} training samples...\")\n",
    "        train_df = train_df.sample(n=config.max_train_samples, random_state=42)\n",
    "\n",
    "    if len(val_df) > config.max_val_samples:\n",
    "        print(f\"Sampling {config.max_val_samples} from {len(val_df)} validation samples...\")\n",
    "        val_df = val_df.sample(n=config.max_val_samples, random_state=42)\n",
    "\n",
    "    if len(test_df) > config.max_test_samples:\n",
    "        print(f\"Sampling {config.max_test_samples} from {len(test_df)} test samples...\")\n",
    "        test_df = test_df.sample(n=config.max_test_samples, random_state=42)\n",
    "\n",
    "    print(f\"Train samples: {len(train_df)}\")\n",
    "    print(f\"Validation samples: {len(val_df)}\")\n",
    "    print(f\"Test samples: {len(test_df)}\")\n",
    "    print()\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = SummarizationDataset(train_df, tokenizer, config.max_seq_len, config.max_summary_len)\n",
    "    val_dataset = SummarizationDataset(val_df, tokenizer, config.max_seq_len, config.max_summary_len)\n",
    "    test_dataset = SummarizationDataset(test_df, tokenizer, config.max_seq_len, config.max_summary_len)\n",
    "\n",
    "    # Create dataloaders with optimizations\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=config.num_workers,\n",
    "        pin_memory=config.pin_memory,\n",
    "        persistent_workers=True if config.num_workers > 0 else False\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=config.num_workers,\n",
    "        pin_memory=config.pin_memory,\n",
    "        persistent_workers=True if config.num_workers > 0 else False\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=config.num_workers,\n",
    "        pin_memory=config.pin_memory,\n",
    "        persistent_workers=True if config.num_workers > 0 else False\n",
    "    )\n",
    "\n",
    "    # Create model\n",
    "    print(\"Step 3: Creating Model\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    model = Transformer(\n",
    "        vocab_size=len(tokenizer.vocab),\n",
    "        d_model=config.d_model,\n",
    "        n_heads=config.n_heads,\n",
    "        n_encoder_layers=config.n_encoder_layers,\n",
    "        n_decoder_layers=config.n_decoder_layers,\n",
    "        d_ff=config.d_ff,\n",
    "        max_seq_len=config.max_seq_len,\n",
    "        dropout=config.dropout\n",
    "    ).to(config.device)\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"Architecture: {config.n_encoder_layers}Ã—Encoder + {config.n_decoder_layers}Ã—Decoder\")\n",
    "\n",
    "    # Compile model for PyTorch 2.0+ (significant speedup)\n",
    "    if config.compile_model and hasattr(torch, 'compile'):\n",
    "        print(\"Compiling model with torch.compile()...\")\n",
    "        try:\n",
    "            model = torch.compile(model, mode='reduce-overhead')\n",
    "            print(\"Model compiled successfully!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not compile model: {e}\")\n",
    "\n",
    "    print()\n",
    "\n",
    "    # Training setup with label smoothing\n",
    "    criterion = nn.CrossEntropyLoss(\n",
    "        ignore_index=tokenizer.special_tokens['<PAD>'],\n",
    "        label_smoothing=config.label_smoothing\n",
    "    )\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=config.learning_rate,\n",
    "        betas=(0.9, 0.98),\n",
    "        eps=1e-9,\n",
    "        weight_decay=0.01,\n",
    "        fused=True if config.device == 'cuda' else False\n",
    "    )\n",
    "\n",
    "    # Learning rate scheduler for better convergence with deeper network\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=config.learning_rate,\n",
    "        epochs=config.n_epochs,\n",
    "        steps_per_epoch=len(train_loader) // config.gradient_accumulation_steps,\n",
    "        pct_start=0.1\n",
    "    )\n",
    "\n",
    "    # Mixed precision training scaler\n",
    "    if config.device == 'cuda':\n",
    "        try:\n",
    "            # Try new API (PyTorch 2.0+)\n",
    "            scaler = torch.amp.GradScaler('cuda')\n",
    "        except (AttributeError, TypeError):\n",
    "            # Fall back to old API\n",
    "            scaler = torch.cuda.amp.GradScaler()\n",
    "    else:\n",
    "        scaler = None\n",
    "\n",
    "    # Load checkpoint if exists\n",
    "    print(\"Step 4: Checking for Existing Checkpoint\")\n",
    "    print(\"-\" * 80)\n",
    "    start_epoch, best_val_loss, train_losses, val_losses, val_bleu_scores = load_checkpoint(\n",
    "        model, optimizer, scheduler, scaler, config\n",
    "    )\n",
    "    print()\n",
    "\n",
    "    # Training loop\n",
    "    print(\"Step 5: Training the Network\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Total epochs: {config.n_epochs}\")\n",
    "    print(f\"Starting from epoch: {start_epoch + 1}\")\n",
    "    print(f\"Total batches per epoch: {len(train_loader)}\")\n",
    "    print(f\"Effective batch size: {config.batch_size * config.gradient_accumulation_steps}\")\n",
    "    print()\n",
    "\n",
    "    for epoch in range(start_epoch, config.n_epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{config.n_epochs}\")\n",
    "        epoch_start_time = torch.cuda.Event(enable_timing=True) if config.device == 'cuda' else None\n",
    "        epoch_end_time = torch.cuda.Event(enable_timing=True) if config.device == 'cuda' else None\n",
    "\n",
    "        if epoch_start_time:\n",
    "            epoch_start_time.record()\n",
    "\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, criterion, config.device, config, scaler)\n",
    "        train_losses.append(train_loss)  # Track training loss\n",
    "\n",
    "        if epoch_end_time:\n",
    "            epoch_end_time.record()\n",
    "            torch.cuda.synchronize()\n",
    "            elapsed_time = epoch_start_time.elapsed_time(epoch_end_time) / 1000.0\n",
    "            print(f\"Epoch time: {elapsed_time:.2f}s\")\n",
    "\n",
    "        # Validate only every N epochs\n",
    "        if (epoch + 1) % config.validate_every_n_epochs == 0:\n",
    "            val_loss, bleu_score = validate(model, val_loader, criterion, config.device, config, \n",
    "                                           tokenizer=tokenizer, compute_bleu=True)\n",
    "            \n",
    "            val_losses.append(val_loss)  # Track validation loss\n",
    "            val_bleu_scores.append(bleu_score)  # Track BLEU score\n",
    "            \n",
    "            if bleu_score is not None:\n",
    "                print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | BLEU: {bleu_score:.4f}\")\n",
    "            else:\n",
    "                print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                save_checkpoint(epoch, model, optimizer, scheduler, scaler, val_loss, \n",
    "                              train_losses, val_losses, val_bleu_scores, config)\n",
    "        else:\n",
    "            val_losses.append(None)  # No validation this epoch\n",
    "            val_bleu_scores.append(None)  # No BLEU this epoch\n",
    "            print(f\"Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "    print()\n",
    "    print(\"Training completed!\")\n",
    "    print()\n",
    "\n",
    "    # Plot training curves\n",
    "    print(\"Step 6: Plotting Training Curves\")\n",
    "    print(\"-\" * 80)\n",
    "    plot_training_curves(train_losses, val_losses, val_bleu_scores, save_path='training_curves.png')\n",
    "    print()\n",
    "\n",
    "    # Load best model\n",
    "    checkpoint = torch.load(config.model_file, weights_only=False)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    # Evaluation with BLEU\n",
    "    print(\"Step 7: Final Evaluation\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    beam_search = BeamSearch(model, tokenizer, beam_size=config.beam_size,\n",
    "                            max_len=config.max_summary_len, length_penalty=config.length_penalty)\n",
    "    bleu_scorer = BLEUScore()\n",
    "\n",
    "    references = []\n",
    "    hypotheses = []\n",
    "    examples = []\n",
    "\n",
    "    model.eval()\n",
    "    batch_count = 0\n",
    "    print(f\"Generating summaries (max {config.max_generation_batches} batches)...\")\n",
    "\n",
    "    for i, batch in enumerate(tqdm(test_loader, desc='Generating summaries')):\n",
    "        if batch_count >= config.max_generation_batches:\n",
    "            break\n",
    "\n",
    "        src = batch['article'].to(config.device)\n",
    "        tgt = batch['summary'].to(config.device)\n",
    "        src_mask, _ = create_masks(src, tgt)\n",
    "\n",
    "        # Generate summaries\n",
    "        with torch.no_grad():\n",
    "            generated = beam_search.generate(src, src_mask)\n",
    "\n",
    "        for j in range(len(generated)):\n",
    "            # Reference\n",
    "            ref_ids = tgt[j].cpu().tolist()\n",
    "            ref_ids = [id for id in ref_ids if id not in [tokenizer.special_tokens['<PAD>'],\n",
    "                                                           tokenizer.special_tokens['<SOS>'],\n",
    "                                                           tokenizer.special_tokens['<EOS>']]]\n",
    "            references.append(ref_ids)\n",
    "\n",
    "            # Hypothesis\n",
    "            hyp_ids = [id for id in generated[j] if id not in [tokenizer.special_tokens['<PAD>'],\n",
    "                                                                tokenizer.special_tokens['<SOS>'],\n",
    "                                                                tokenizer.special_tokens['<EOS>']]]\n",
    "            hypotheses.append(hyp_ids)\n",
    "\n",
    "            # Save examples\n",
    "            if len(examples) < config.top_k_summaries:\n",
    "                article_ids = src[j].cpu().tolist()\n",
    "                article_ids = [id for id in article_ids if id not in [tokenizer.special_tokens['<PAD>']]]\n",
    "\n",
    "                examples.append({\n",
    "                    'article': tokenizer.decode(article_ids),\n",
    "                    'reference': tokenizer.decode(ref_ids),\n",
    "                    'generated': tokenizer.decode(hyp_ids)\n",
    "                })\n",
    "\n",
    "        batch_count += 1\n",
    "\n",
    "    # Compute BLEU\n",
    "    bleu_results = bleu_scorer.compute(references, hypotheses)\n",
    "\n",
    "    print(f\"\\nBLEU Score: {bleu_results['bleu']:.4f}\")\n",
    "    print(f\"Brevity Penalty: {bleu_results['brevity_penalty']:.4f}\")\n",
    "    print(f\"Length Ratio: {bleu_results['length_ratio']:.4f}\")\n",
    "    for i, prec in enumerate(bleu_results['precisions'], 1):\n",
    "        print(f\"Precision-{i}: {prec:.4f}\")\n",
    "    print()\n",
    "\n",
    "    # Display top examples\n",
    "    print(f\"Step 8: Top {config.top_k_summaries} Generated Summaries\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    for i, example in enumerate(examples, 1):\n",
    "        print(f\"\\nExample {i}:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"Article (truncated): {example['article'][:200]}...\")\n",
    "        print(f\"\\nReference Summary: {example['reference']}\")\n",
    "        print(f\"\\nGenerated Summary: {example['generated']}\")\n",
    "        print()\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"DONE!\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "998adc4c-a339-4e48-b544-28b7a913221a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DEEPER TRANSFORMER TEXT SUMMARIZATION (WITH RESUME CAPABILITY)\n",
      "================================================================================\n",
      "Device: cuda\n",
      "Model Depth: 8 encoder layers, 8 decoder layers\n",
      "\n",
      "Step 1: Loading/Training Tokenizer\n",
      "--------------------------------------------------------------------------------\n",
      "Loading tokenizer from bpe_tokenizer_all.pkl\n",
      "Tokenizer loaded successfully!\n",
      "Vocabulary size: 50000\n",
      "Saving vocabulary...\n",
      "âœ“ Vocabulary saved to vocabulary.pkl\n",
      "\n",
      "Step 2: Loading Datasets\n",
      "--------------------------------------------------------------------------------\n",
      "Sampling 250 from 287113 training samples...\n",
      "Sampling 100 from 13368 validation samples...\n",
      "Sampling 100 from 11490 test samples...\n",
      "Train samples: 250\n",
      "Validation samples: 100\n",
      "Test samples: 100\n",
      "\n",
      "Step 3: Creating Model\n",
      "--------------------------------------------------------------------------------\n",
      "Total parameters: 135,703,376\n",
      "Trainable parameters: 135,703,376\n",
      "Architecture: 8Ã—Encoder + 8Ã—Decoder\n",
      "\n",
      "Step 4: Checking for Existing Checkpoint\n",
      "--------------------------------------------------------------------------------\n",
      "Loading checkpoint from transformer_summarization_deep.pt...\n",
      "âœ“ Model state loaded\n",
      "âœ“ Optimizer state loaded\n",
      "âœ“ Scheduler state loaded\n",
      "âœ“ Scaler state loaded\n",
      "âœ“ Resuming from epoch 37\n",
      "âœ“ Best validation loss: 5.2753\n",
      "âœ“ Loaded 0 training loss records\n",
      "\n",
      "Step 5: Training the Network\n",
      "--------------------------------------------------------------------------------\n",
      "Total epochs: 37\n",
      "Starting from epoch: 38\n",
      "Total batches per epoch: 11\n",
      "Effective batch size: 48\n",
      "\n",
      "\n",
      "Training completed!\n",
      "\n",
      "Step 6: Plotting Training Curves\n",
      "--------------------------------------------------------------------------------\n",
      "âœ“ Training curves saved to training_curves.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 7: Final Evaluation\n",
      "--------------------------------------------------------------------------------\n",
      "Generating summaries (max 100 batches)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating summaries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:47<00:00,  9.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BLEU Score: 0.0368\n",
      "Brevity Penalty: 0.8009\n",
      "Length Ratio: 0.8183\n",
      "Precision-1: 0.3342\n",
      "Precision-2: 0.0692\n",
      "Precision-3: 0.0228\n",
      "Precision-4: 0.0084\n",
      "\n",
      "Step 8: Top 5 Generated Summaries\n",
      "================================================================================\n",
      "\n",
      "Example 1:\n",
      "--------------------------------------------------------------------------------\n",
      "Article (truncated): comedian jenny e clair travelled with her other half on a painting in venus break with flavours . there comes a time in a womans life when beach holidays just dont cut it any longer, when lying on gol...\n",
      "\n",
      "Reference Summary: the comedian stayed with flavours who offer a painting in venice break . jenny and her partner ge of stayed at the farmhouse villa bianchi . days involved sitting in medieval market towns with a brush and prose c co .\n",
      "\n",
      "Generated Summary: comic book artist jenny stone takes inspiration from all over the world . she takes inspiration from all over the world and the rest of the world . highlights include fine art and art of art and art .\n",
      "\n",
      "\n",
      "Example 2:\n",
      "--------------------------------------------------------------------------------\n",
      "Article (truncated): a woman of arab and jewish descent who was strip - searched at a detroit - area airport has reached a settlement in a lawsuit filed on her behalf, the american civil liberties union said tuesday. the ...\n",
      "\n",
      "Reference Summary: the federal government will give sho sh ana heb shi 40,000 as compensation for being ethnically profiled . heb sh i, who has a jewish mother and saudi arabian father, has said she was discriminated against based on her dark complexion . heb shi was detained along with two indian men she was seated next to . 'people do not forfeit their constitutional\n",
      "\n",
      "Generated Summary: sh ana shi sh i, a civil rights activist at sh ana city, missouri, was charged with violating the civil rights act by the civil rights act . the civil lawsuit was filed on behalf of the civil aviation authority in detroit and the u.s. supreme court of justice . sh ana was awarded the medal of freedom in 2011 for violating the\n",
      "\n",
      "\n",
      "Example 3:\n",
      "--------------------------------------------------------------------------------\n",
      "Article (truncated): world no 1 novak djokovic has apologised to the startled ball boy caught in the crossfire of a tirade at his support team during his win over andy murray in sunday's miami open final. djokovic lost hi...\n",
      "\n",
      "Reference Summary: novak djokovic beat andy murray 7-6 4-6 6-0 in miami open 2015 final . djokovic lost his cool after losing the second set to the brit in florida . world no 1 djokovic shouted at his support team next to a scared ball boy . after seeing the re play, the serbian posted an apology video on facebook . click here for all\n",
      "\n",
      "Generated Summary: novak djokovic lost the ball to novak djokovic in the second round match . the boy was caught by a fan during the match in miami . he then posted a picture of the boy and said he was sorry for the incident . djokovic later apologised and apologised for the incident .\n",
      "\n",
      "\n",
      "Example 4:\n",
      "--------------------------------------------------------------------------------\n",
      "Article (truncated): cnn isis on wednesday released more than 200 yaz id is, a minority group whose members were killed, captured and displaced when the islamist terror organization overtook their towns in northern iraq l...\n",
      "\n",
      "Reference Summary: most of those released were women and children . freed yazidis sent to capital of iraq's kurdish region .\n",
      "\n",
      "Generated Summary: the united states released a series of airstrikes against isis militants in northern iraq . the airstrikes took place in northern iraq and syria .\n",
      "\n",
      "\n",
      "Example 5:\n",
      "--------------------------------------------------------------------------------\n",
      "Article (truncated): hillary clintons security detail arrived at a suburban des moines, iowa fruit processing company on tuesday with an added vehicle a second sco o by. after her signature over size black chevy conversio...\n",
      "\n",
      "Reference Summary: second modified , armored van spotted near des moines, iowa alongside the one that hillary clinton travels in . visually identical black vehicles ' biggest difference is the color of their new york license plates . one is a chevy and the other a gmc but they are mechan ically identical and one was seen using secret service - fitted red and blue\n",
      "\n",
      "Generated Summary: hillary clinton was spotted at the fe o o highway in iowa on tuesday . the pair had a pair of white wings and a pair of jeans .\n",
      "\n",
      "================================================================================\n",
      "DONE!\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
